<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>LinearRegression.jl Documentation · LinearRegression.jl</title><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>LinearRegression.jl</a></span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>LinearRegression.jl Documentation</a><ul class="internal"><li><a class="tocitem" href="#Functions"><span>Functions</span></a></li><li><a class="tocitem" href="#Index"><span>Index</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>LinearRegression.jl Documentation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>LinearRegression.jl Documentation</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/ericqu/LinearRegression.jl/blob/master/docs/src/index.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="LinearRegression.jl-Documentation"><a class="docs-heading-anchor" href="#LinearRegression.jl-Documentation">LinearRegression.jl Documentation</a><a id="LinearRegression.jl-Documentation-1"></a><a class="docs-heading-anchor-permalink" href="#LinearRegression.jl-Documentation" title="Permalink"></a></h1><ul><li><a href="#LinearRegression.jl-Documentation">LinearRegression.jl Documentation</a></li><li class="no-marker"><ul><li><a href="#Functions">Functions</a></li><li><a href="#Index">Index</a></li></ul></li></ul><p>LinearRegression.jl implements linear regression using the least-squares algorithm (relying on the sweep operator). This package is in the alpha stage. Hence it is likely that some bugs exist. Furthermore, the API might change in future versions.</p><p>The usage aims to be straightforward, a call to <code>regress</code> to build a linear regression model, and a call to <code>predict_in_sample</code> to predict data using the built linear regression model. When predicting on data not present during the regression, use the <code>predict_out_of_sample</code> function as this does not require a response value (consequently statistics that require a response, like the residuals are not available.)</p><p>The regress call will compute some statistics about the fitted model in addition to the coefficients. Which statistics is computed is dependent on which value receive the <code>req_stats</code> argument. </p><h4 id="Number-of-observations-and-variables"><a class="docs-heading-anchor" href="#Number-of-observations-and-variables">Number of observations and variables</a><a id="Number-of-observations-and-variables-1"></a><a class="docs-heading-anchor-permalink" href="#Number-of-observations-and-variables" title="Permalink"></a></h4><p>The number of observations <span>$n$</span> used to fit the model.</p><p>The number of independent variables <span>$p$</span> used in the model.</p><h4 id="Total-Sum-of-Squares"><a class="docs-heading-anchor" href="#Total-Sum-of-Squares">Total Sum of Squares</a><a id="Total-Sum-of-Squares-1"></a><a class="docs-heading-anchor-permalink" href="#Total-Sum-of-Squares" title="Permalink"></a></h4><p>The Total Sum of Squares (SST) is calculated but not presented to the user. In case of model with intercept the SST is computed with the following:</p><p class="math-container">\[\mathrm{SST}=\sum_{i=1}^{n}\left(y_{i}-\bar{y}\right)^2\]</p><p>And when there is no intercept with the following: </p><p class="math-container">\[\mathrm{SST}=\sum_{i=1}^{n} y_{i}^2\]</p><h4 id="Error-Sum-of-Squares"><a class="docs-heading-anchor" href="#Error-Sum-of-Squares">Error Sum of Squares</a><a id="Error-Sum-of-Squares-1"></a><a class="docs-heading-anchor-permalink" href="#Error-Sum-of-Squares" title="Permalink"></a></h4><p>The Error Sum of Squares (or SSE) also known as Residual Sum of Square (RSS). This package uses the sweep operator (Goodnight, J. (1979). &quot;A Tutorial on the SWEEP Operator.&quot; The American Statistician.) to compute the SSE.</p><h4 id="Mean-Squared-Error"><a class="docs-heading-anchor" href="#Mean-Squared-Error">Mean Squared Error</a><a id="Mean-Squared-Error-1"></a><a class="docs-heading-anchor-permalink" href="#Mean-Squared-Error" title="Permalink"></a></h4><p>The Mean Squared Error (MSE) is calculated as </p><p class="math-container">\[\mathrm{MSE} = \displaystyle{\frac{{\mathrm{SSE}}}{{n - p}}}\]</p><p>The Root Mean Squared Error (RMSE) is calculated as </p><p class="math-container">\[\mathrm{RMSE} = \sqrt{\mathrm{MSE}}\]</p><p>The MSE is the estimator of σ̂² unless at least one robust covariance estimator is requested.</p><h4 id="R-and-Adjusted-R"><a class="docs-heading-anchor" href="#R-and-Adjusted-R">R² and Adjusted R²</a><a id="R-and-Adjusted-R-1"></a><a class="docs-heading-anchor-permalink" href="#R-and-Adjusted-R" title="Permalink"></a></h4><p>The R² (R2 or R-squared) see (https://en.wikipedia.org/wiki/Coefficient<em>of</em>determination) is calculated with the following formula: </p><p class="math-container">\[\mathrm{R}^2 = 1 - \displaystyle{\frac{{\mathrm{SSE}}}{{\mathrm{SST}}}}\]</p><p>The Adjusted R² (ADJR2) is computed with the following formulas:</p><p>when it is a model with an intercept:</p><p class="math-container">\[\mathrm{ADJR}^2 = 1 - \displaystyle \frac{(n-1)(1-\mathrm{R}^2)}{n-p}\]</p><p>And when there is no intercept:</p><p class="math-container">\[\mathrm{ADJR}^2 = 1 - \displaystyle \frac{(n)(1-\mathrm{R}^2)}{n-p}\]</p><h4 id="Akaike-information-criterion"><a class="docs-heading-anchor" href="#Akaike-information-criterion">Akaike information criterion</a><a id="Akaike-information-criterion-1"></a><a class="docs-heading-anchor-permalink" href="#Akaike-information-criterion" title="Permalink"></a></h4><p>The Akaike information criterion is calculated with the Linear Regression specific formula:</p><p class="math-container">\[\mathrm{AIC} = \displaystyle n \ln \left( \frac{\mathrm{SSE}}{n} \right) + 2p\]</p><h4 id="t-statistic-and-confidence-interval"><a class="docs-heading-anchor" href="#t-statistic-and-confidence-interval">t-statistic and confidence interval</a><a id="t-statistic-and-confidence-interval-1"></a><a class="docs-heading-anchor-permalink" href="#t-statistic-and-confidence-interval" title="Permalink"></a></h4><p>The t-statistic is computed by using the inverse cumulative t-distribution (with <code>quantile()</code>) with parameter (<span>$n - p$</span>) at <span>$1 - \frac{α}{2}$</span>. </p><p>The standard errors of the coefficients are calculated by multiplying the Sigma (estimated by the MSE) with the pseudo inverse matrix (resulting from the sweep operator), out of which the square root of the diagonal elements are extracted.</p><p>The t-values are calculated as the coefficients divided by their standard deviation.</p><p>The upper bound of the confidence interval for each coefficient is calculated as the coeffiecent + coefficient&#39;s standard error * t_statistic.</p><p>The lower bound of the confidence interval for each coefficient is calculated as the coeffiecent - coefficient&#39;s standard error * t_statistic.</p><h4 id="p-values"><a class="docs-heading-anchor" href="#p-values">p-values</a><a id="p-values-1"></a><a class="docs-heading-anchor-permalink" href="#p-values" title="Permalink"></a></h4><p>The p-values are computed using the F Distribution, the degree of freedom for each coefficent.</p><h4 id="Variance-inflation-factor"><a class="docs-heading-anchor" href="#Variance-inflation-factor">Variance inflation factor</a><a id="Variance-inflation-factor-1"></a><a class="docs-heading-anchor-permalink" href="#Variance-inflation-factor" title="Permalink"></a></h4><p>Variance inflation factor (VIF) is calculated by taking the  diagonal elements of the inverse of the correlation matrix formed by the independent variables.</p><h3 id="Robust-covariance-estimators"><a class="docs-heading-anchor" href="#Robust-covariance-estimators">Robust covariance estimators</a><a id="Robust-covariance-estimators-1"></a><a class="docs-heading-anchor-permalink" href="#Robust-covariance-estimators" title="Permalink"></a></h3><h4 id="Heteroscedasticity-estimators"><a class="docs-heading-anchor" href="#Heteroscedasticity-estimators">Heteroscedasticity estimators</a><a id="Heteroscedasticity-estimators-1"></a><a class="docs-heading-anchor-permalink" href="#Heteroscedasticity-estimators" title="Permalink"></a></h4><p>The user can select estimators from these list. If the user select &quot;White&quot; as an estimator then HC3 will be selected for a small size (n &lt; 250) otherwise HC0 will be selected.</p><h5 id="HC0"><a class="docs-heading-anchor" href="#HC0">HC0</a><a id="HC0-1"></a><a class="docs-heading-anchor-permalink" href="#HC0" title="Permalink"></a></h5><p>The following estimators can be calculated. Having InvMat the pseudo inverse resulting from the sweep operator. And having <span>$xe$</span> being the matrix of the independent variables times the residuals. Then HC0 is calculated as:</p><p class="math-container">\[\textup{HC0} = \sqrt{diag(\textup{InvMat } \textup{xe}&#39; \textup{xe} \textup{ InvMat})}\]</p><h5 id="HC1"><a class="docs-heading-anchor" href="#HC1">HC1</a><a id="HC1-1"></a><a class="docs-heading-anchor-permalink" href="#HC1" title="Permalink"></a></h5><p>Having n being the number of observations and p the number of variables. Then HC1 is calculated as:</p><p class="math-container">\[\textup{HC1} = \sqrt{diag(\textup{InvMat } \textup{xe}&#39; \textup{xe} \textup{ InvMat } \frac{n}{n-p})}\]</p><h5 id="HC2"><a class="docs-heading-anchor" href="#HC2">HC2</a><a id="HC2-1"></a><a class="docs-heading-anchor-permalink" href="#HC2" title="Permalink"></a></h5><p>The leverage or hat matrix is calculated as:</p><p class="math-container">\[\textup{H} = \textup{X} (\textup{X&#39;X})^{-1}\textup{X&#39;}\]</p><p><span>$xe$</span> is scaled by <span>$\frac{1}{1 - H}$</span> then </p><p class="math-container">\[\textup{HC2} = \sqrt{diag(\textup{InvMat } \textup{xe}&#39; \textup{xe} \textup{ InvMat } )}\]</p><h5 id="HC3"><a class="docs-heading-anchor" href="#HC3">HC3</a><a id="HC3-1"></a><a class="docs-heading-anchor-permalink" href="#HC3" title="Permalink"></a></h5><p><span>$xe$</span> is scaled by <span>$\frac{1}{{\left( 1 - H \right)^2}}$</span> then </p><p class="math-container">\[\textup{HC3} = \sqrt{diag(\textup{InvMat } \textup{xe}&#39; \textup{xe} \textup{ InvMat } )}\]</p><h4 id="Heteroskedasticity-and-autocorrelation-consistent-estimator"><a class="docs-heading-anchor" href="#Heteroskedasticity-and-autocorrelation-consistent-estimator">Heteroskedasticity and autocorrelation consistent estimator</a><a id="Heteroskedasticity-and-autocorrelation-consistent-estimator-1"></a><a class="docs-heading-anchor-permalink" href="#Heteroskedasticity-and-autocorrelation-consistent-estimator" title="Permalink"></a></h4><p>Newey-West estimator calculation is not documented yet. See <a href="https://github.com/mcreel/Econometrics/blob/508aee681ca42ff1f361fd48cd64de6565ece221/src/NP/NeweyWest.jl">reference implementation</a> <a href="https://github.com/ericqu/LinearRegression.jl/blob/docu/src/newey_west.jl">current implementation</a> for details.</p><h4 id="Weighted-regression"><a class="docs-heading-anchor" href="#Weighted-regression">Weighted regression</a><a id="Weighted-regression-1"></a><a class="docs-heading-anchor-permalink" href="#Weighted-regression" title="Permalink"></a></h4><p>This version is the initial implementation of a weighted regression using analytical weights. Here is a minimal example illustrating its usage.</p><pre><code class="language-julia hljs">tw = [
    2.3  7.4  0.058 
    3.0  7.6  0.073 
    2.9  8.2  0.114 
    4.8  9.0  0.144 
    1.3 10.4  0.151 
    3.6 11.7  0.119 
    2.3 11.7  0.119 
    4.6 11.8  0.114 
    3.0 12.4  0.073 
    5.4 12.9  0.035 
    6.4 14.0  0
] # data from https://blogs.sas.com/content/iml/2016/10/05/weighted-regression.html

df = DataFrame(tw, [:y,:x,:w])
f = @formula(y ~ x)
lm, ps= regress(f, df, &quot;fit&quot;, weights=&quot;w&quot;)</code></pre><p>Which gives the following output:</p><pre><code class="nohighlight hljs">Model definition:      y ~ 1 + x
Used observations:      3
Weighted regression
Model statistics:
  R²: 0.96                      Adjusted R²: 0.92
  MSE: 0.48                     RMSE: 0.69282
  σ̂²: 0.48
Confidence interval: 95%

Coefficients statistics:
Terms ╲ Stats │     Coefs    Std err          t   Pr(&gt;|t|)     low ci    high ci
──────────────┼─────────────────────────────────────────────────────────────────
(Intercept)   │      -0.2    0.69282  -0.288675   0.821088   -9.00312    8.60312
x             │      1.44   0.293939    4.89898   0.128188   -2.29485    5.17485</code></pre><h2 id="Functions"><a class="docs-heading-anchor" href="#Functions">Functions</a><a id="Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Functions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="LinearRegression.regress-Tuple{FormulaTerm, DataFrame, Any}" href="#LinearRegression.regress-Tuple{FormulaTerm, DataFrame, Any}"><code>LinearRegression.regress</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">function regress(f::StatsModels.FormulaTerm, df::DataFrames.DataFrame, req_plots; α::Float64=0.05, req_stats=[&quot;default&quot;],
weights::Union{Nothing,String}=nothing, remove_missing=false, cov=[:none], contrasts=nothing, 
plot_args=Dict(&quot;plot_width&quot; =&gt; 400, &quot;loess_bw&quot; =&gt; 0.6, &quot;residuals_with_density&quot; =&gt; false))

Estimate the coefficients of the regression, given a dataset and a formula. and provide the requested plot(s).
A dictionary of the generated plots indexed by the descritption of the plots.

It is possible to indicate the width of the plots, and the bandwidth of the Loess smoother.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ericqu/LinearRegression.jl/blob/97916bc4db67589ed5e1009483e34dcfc8e7a92d/src/LinearRegression.jl#L238-L248">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearRegression.regress-Tuple{FormulaTerm, DataFrame}" href="#LinearRegression.regress-Tuple{FormulaTerm, DataFrame}"><code>LinearRegression.regress</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">function regress(f::StatsModels.FormulaTerm, df::DataFrames.DataFrame; α::Float64=0.05, req_stats=[&quot;default&quot;], weights::Union{Nothing,String}=nothing,
remove_missing=false, cov=[:none], contrasts=nothing)

Estimate the coefficients of the regression, given a dataset and a formula. 

The formula details are provided in the StatsModels package and the behaviour aims to be similar as what the Julia GLM package provides.
The data shall be provided as a DataFrame without missing data.
If remove_missing is set to true a copy of the dataframe will be made and the row with missing data will be removed.
Some robust covariance estimator(s) can be requested through the ```cov``` argument.
Default contrast is dummy coding, other contrasts can be requested through the ```contrasts``` argument.
For a weighted regression, the name of column containing the analytical weights shall be identified by the ```weights``` argument.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ericqu/LinearRegression.jl/blob/97916bc4db67589ed5e1009483e34dcfc8e7a92d/src/LinearRegression.jl#L280-L293">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearRegression.predict_in_sample-Tuple{linRegRes, DataFrame}" href="#LinearRegression.predict_in_sample-Tuple{linRegRes, DataFrame}"><code>LinearRegression.predict_in_sample</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">predict_in_sample(lr::linRegRes, df::DataFrames.DataFrame; α=0.05, req_stats=[&quot;none&quot;], dropmissingvalues=true)

Using the estimated coefficients from the regression make predictions, and calculate related statistics.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ericqu/LinearRegression.jl/blob/97916bc4db67589ed5e1009483e34dcfc8e7a92d/src/LinearRegression.jl#L673-L677">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearRegression.predict_out_of_sample-Tuple{linRegRes, DataFrame}" href="#LinearRegression.predict_out_of_sample-Tuple{linRegRes, DataFrame}"><code>LinearRegression.predict_out_of_sample</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">function predict_out_of_sample(lr::linRegRes, df::DataFrames.DataFrame; α=0.05, req_stats=[&quot;none&quot;], dropmissingvalues=true)

use the coefficients from a regression make predictions based on data (not including the response variable) from a DataFrame.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ericqu/LinearRegression.jl/blob/97916bc4db67589ed5e1009483e34dcfc8e7a92d/src/LinearRegression.jl#L584-L588">source</a></section></article><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><ul><li><a href="#LinearRegression.predict_in_sample-Tuple{linRegRes, DataFrame}"><code>LinearRegression.predict_in_sample</code></a></li><li><a href="#LinearRegression.predict_out_of_sample-Tuple{linRegRes, DataFrame}"><code>LinearRegression.predict_out_of_sample</code></a></li><li><a href="#LinearRegression.regress-Tuple{FormulaTerm, DataFrame}"><code>LinearRegression.regress</code></a></li><li><a href="#LinearRegression.regress-Tuple{FormulaTerm, DataFrame, Any}"><code>LinearRegression.regress</code></a></li></ul></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.10 on <span class="colophon-date" title="Monday 1 November 2021 01:32">Monday 1 November 2021</span>. Using Julia version 1.6.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
